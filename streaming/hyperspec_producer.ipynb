{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d365cd-bd03-49e6-be5c-73ef46373e34",
   "metadata": {},
   "source": [
    "# Initial Producer\n",
    "This is the initial producer in the streaming pipeline. This should run on the computer dedicated to the hyperspectral camera and stream raw data out to the PARADIM broker when it is captured. The code is structured off of notebooks at github.com/openmsi/openmsistream_short_course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf636f-ecd3-40c5-b176-c12424ee9d3a",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f736f37-4310-4de7-9e59-3f708e54bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pathlib, logging, importlib\n",
    "from threading import Thread\n",
    "from openmsitoolbox.logging import OpenMSILogger\n",
    "from openmsistream import UploadDataFile, DataFileUploadDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cd4359-5531-4138-9fff-515916fef4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'logging' from '/Users/namanparikh/opt/anaconda3/envs/openmsi/lib/python3.9/logging/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure a logger (only needed when running in a Jupyter notebook like this)\n",
    "logger = OpenMSILogger(\"LocalProducer\", filelevel=None)\n",
    "importlib.reload(logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7181fd8-1bab-4ea3-bf9b-33b6e2375f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the topic to work with\n",
    "TOPIC_NAME = \"tutorial_data\"\n",
    "\n",
    "# Paths to the config file and the directory holding the test files\n",
    "repo_root_dir = pathlib.Path().resolve().parent\n",
    "CONFIG_FILE_PATH = repo_root_dir / \"streaming\" / \"config_files\" / \"confluent_cloud_broker.config\"\n",
    "TEST_FILE_DIR = repo_root_dir / \"streaming\" / \"test_folder\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf45d4-f7d3-46aa-a05b-ca74baab0eb4",
   "metadata": {},
   "source": [
    "## UploadDataFile (to test)\n",
    "can you set it up so that each image folder is uploaded as a separate message?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c0990c-0ebc-4e17-8afd-42dbfa921365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/config_files/confluent_cloud_broker.config')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a72b9b1-5f45-4070-abea-c92e0b0546aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_FILE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfde5ec-2080-4e8a-a5e2-04ac01d97647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/.DS_Store\n",
      "1 /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/test_data.txt\n",
      "2 /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/LOGS\n",
      "3 /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/.ipynb_checkpoints\n",
      "4 /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/LOGS/upload_to_tutorial_data_in_progress.csv\n",
      "5 /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/.ipynb_checkpoints/test_data-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "for iuf, upload_file_path in enumerate(TEST_FILE_DIR.rglob(\"*\")):\n",
    "    print(iuf, upload_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bda59f-0910-4bd7-b9c5-b0b7a39b5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LocalProducer 2024-07-18 00:00:59] Uploading /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/test_data.txt to tutorial_data in 524288-byte chunks using 2 threads....\n",
      "[LocalProducer 2024-07-18 00:01:00] Waiting for all enqueued messages to be delivered (this may take a moment)....\n",
      "[LocalProducer 2024-07-18 00:01:00] Done uploading /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/test_data.txt\n",
      "[LocalProducer 2024-07-18 00:01:00] Uploading /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/.ipynb_checkpoints/test_data-checkpoint.txt to tutorial_data in 524288-byte chunks using 2 threads....\n",
      "[LocalProducer 2024-07-18 00:01:00] Waiting for all enqueued messages to be delivered (this may take a moment)....\n",
      "[LocalProducer 2024-07-18 00:01:01] Done uploading /Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder/.ipynb_checkpoints/test_data-checkpoint.txt\n"
     ]
    }
   ],
   "source": [
    "# For every file in the folder\n",
    "for iuf, upload_file_path in enumerate(TEST_FILE_DIR.rglob(\"*\")):\n",
    "    # Skip any hidden files (like .DS_Store....)\n",
    "    if upload_file_path.is_dir() or upload_file_path.name.startswith(\".\"):\n",
    "        continue\n",
    "    # Create an UploadDataFile and call the function to upload it to the topic\n",
    "    upload_file = UploadDataFile(upload_file_path, rootdir=TEST_FILE_DIR, logger=logger)\n",
    "    upload_file.upload_whole_file(CONFIG_FILE_PATH, TOPIC_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cdd15-489f-40fe-956c-886a712a316b",
   "metadata": {},
   "source": [
    "## DataUploadFileDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1a55ea9-9356-4030-ba9d-df34128af7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_task(upload_directory, *args, **kwargs):\n",
    "    \"\"\"Run \"upload_files_as_added\" for a given DataFileUploadDirectory, and log a message\n",
    "    when it gets shut down\n",
    "\n",
    "    Args:\n",
    "        upload_directory (DataFileUploadDirectory): the DataFileUploadDirectory to run\n",
    "        args (list): passed through to \"upload_files_as_added\"\n",
    "        kwargs (dict): passed through to \"upload_files_as_added\"\n",
    "    \"\"\"\n",
    "    # This call to \"upload_files_as_added\" waits until the program is shut down\n",
    "    uploaded_filepaths = upload_directory.upload_files_as_added(*args, **kwargs)\n",
    "    msg = (\n",
    "        f\"The following files were uploaded:\\n\\t\"\n",
    "    )\n",
    "    msg += \"\\n\\t\".join([str(fp) for fp in uploaded_filepaths])\n",
    "    upload_directory.logger.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5763d6-a6fc-4160-ab7c-ad3c1bd35069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LocalProducer 2024-07-18 00:17:41] Will upload new files added to/Users/namanparikh/Documents/GitHub/paradim/reu2024-hyperspectral-camera/streaming/test_folder to the tutorial_data topic as 524288-byte chunks using 2 threads\n",
      "[LocalProducer 2024-07-18 00:18:09] Will quit after all currently enqueued files are done being transferred.\n",
      "[LocalProducer 2024-07-18 00:18:09] Waiting for all enqueued messages to be delivered (this may take a moment)\n",
      "[LocalProducer 2024-07-18 00:18:09] The following files were uploaded:\n",
      "\ttest_watchdog.txt\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFileUploadDirectory\n",
    "dfud = DataFileUploadDirectory(TEST_FILE_DIR, CONFIG_FILE_PATH, logger=logger)\n",
    "# Start running its \"upload_files_as_added\" function in a separate thread\n",
    "upload_thread = Thread(\n",
    "    target=upload_task,\n",
    "    args=(\n",
    "        dfud,\n",
    "        TOPIC_NAME,\n",
    "    ),\n",
    ")\n",
    "upload_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d168ec-56dc-4e96-8a63-cfdadf3a41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually shut down the upload directory (if running from the command line this would\n",
    "# be like typing \"q\" in the Terminal window)\n",
    "dfud.control_command_queue.put(\"q\")\n",
    "upload_thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
